{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, tune, and deploy a custom ML model using <font color='red'>Optimize Next Best Action Prediction</font> Algorithm from AWS Marketplace \n",
    "\n",
    "\n",
    "<font color='red'> A deep learning based solution that analyzes event (e.g. loan approval process) log data with contextual information (e.g. loan request parameters, etc.) and predicts the next step and time to next step for an open request within a process. With process execution data stored in form of event logs, an AI based operations planning system can help in understanding future system state based on current state and business context. This solution improves business operations planning by reducing cost and improving efficiency through dynamic resource planning. </font>\n",
    "\n",
    "This sample notebook shows you how to train a custom ML model using <font color='red'>  [Optimize Next Best Action Prediction](https://aws.amazon.com/marketplace/pp/prodview-abpjqnkcxrmhq?qid=1614675374394&sr=0-1&ref_=srh_res_product_title)</font> from AWS Marketplace.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to <font color='red'>  [Optimize Next Best Action Prediction](https://aws.amazon.com/marketplace/pp/prodview-abpjqnkcxrmhq?qid=1614675374394&sr=0-1&ref_=srh_res_product_title)</font>. \n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "\t1. [Dataset format expected by the algorithm](#A.-Dataset-format-expected-by-the-algorithm)\n",
    "\t1. [Configure and visualize train and test dataset](#B.-Configure-and-visualize-train-and-test-dataset)\n",
    "\t1. [Upload datasets to Amazon S3](#C.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Train a machine learning model](#3:-Train-a-machine-learning-model)\n",
    "\t1. [Set up environment](#3.1-Set-up-environment)\n",
    "\t1. [Train a model](#3.2-Train-a-model)\n",
    "1. [Deploy model and verify results](#4:-Deploy-model-and-verify-results)\n",
    "    1. [Deploy trained model](#A.-Deploy-trained-model)\n",
    "    1. [Create input payload](#B.-Create-input-payload)\n",
    "    1. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "    1. [Visualize output](#D.-Visualize-output)\n",
    "    1. [Calculate relevant metrics](#E.-Calculate-relevant-metrics)\n",
    "    1. [Delete the endpoint](#F.-Delete-the-endpoint)\n",
    "1. [Tune your model! (optional)](#5:-Tune-your-model!-(optional))\n",
    "\t1. [Tuning Guidelines](#A.-Tuning-Guidelines)\n",
    "\t1. [Define Tuning configuration](#B.-Define-Tuning-configuration)\n",
    "\t1. [Run a model tuning job](#C.-Run-a-model-tuning-job)\n",
    "1. [Perform Batch inference](#6.-Perform-Batch-inference)\n",
    "1. [Clean-up](#7.-Clean-up)\n",
    "\t1. [Delete the model](#A.-Delete-the-model)\n",
    "\t1. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "\n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "1. Open the algorithm listing page <font color='red'> [Optimize Next Best Action Prediction](https://aws.amazon.com/marketplace/pp/prodview-abpjqnkcxrmhq?qid=1614675374394&sr=0-1&ref_=srh_res_product_title).</font>\n",
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_arn='arn:aws:sagemaker:us-east-2:786796469737:algorithm/mphasis-marketplace-next-best-action-new-v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json \n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "from IPython.display import Image\n",
    "from PIL import Image as ImageEdit\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deployed solution has these **2 steps**:\n",
    "1. Training API: The system trains on user provided historical process data  with contextual information and builds & saves a deep learning model which is a representation of the process behavior.\n",
    "2. Testing API:  Once the model is generated, the solution can be used to predict next possible step and time to next step for a given open request within a process. \n",
    "\n",
    "** Following are the mandatory inputs for both the APIs:**\n",
    "* *CaseID*: Unique identifier of a request/journey e.g. E-comm order ID, loan ID etc.\n",
    "* *ActivityID*: Activity Identifier/Activity Name performed for each CASE_ID e.g. INVOICE GENERATION, KYC etc.\n",
    "* *CompleteTimestamp*: Timestamp for a unique CASE_ID/ACTIVITY_ID combination.\n",
    "* *context*: Contextual variables can be anything which provides information related to case. E.g. Loan Amount,  Vendor ID etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find more information about dataset format in **Usage Information** section of <font color='red'>  [Optimize Next Best Action Prediction](https://aws.amazon.com/marketplace/pp/prodview-abpjqnkcxrmhq?qid=1614675374394&sr=0-1&ref_=srh_res_product_title).</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Configure and visualize train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset='data/train/sample_train_file.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CaseID</th>\n",
       "      <th>ActivityID</th>\n",
       "      <th>CompleteTimestamp</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4/3/2012 16:55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4/3/2012 16:55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4/5/2012 17:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10/29/2010 18:14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>11/4/2010 1:16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CaseID  ActivityID CompleteTimestamp  context\n",
       "0       2           1    4/3/2012 16:55        1\n",
       "1       2           8    4/3/2012 16:55        1\n",
       "2       2           6    4/5/2012 17:15        1\n",
       "3       3           1  10/29/2010 18:14        5\n",
       "4       3           8    11/4/2010 1:16        5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_df = pd.read_csv(training_dataset)\n",
    "train_input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset='data/test/sample_test_file.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CaseID</th>\n",
       "      <th>ActivityID</th>\n",
       "      <th>CompleteTimestamp</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4350</td>\n",
       "      <td>1</td>\n",
       "      <td>6/30/2011 22:58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4350</td>\n",
       "      <td>1</td>\n",
       "      <td>6/30/2011 22:58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4350</td>\n",
       "      <td>8</td>\n",
       "      <td>7/5/2011 17:27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4350</td>\n",
       "      <td>6</td>\n",
       "      <td>7/19/2011 21:37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4355</td>\n",
       "      <td>1</td>\n",
       "      <td>8/2/2012 17:31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CaseID  ActivityID CompleteTimestamp  context\n",
       "0    4350           1   6/30/2011 22:58        2\n",
       "1    4350           1   6/30/2011 22:58        2\n",
       "2    4350           8    7/5/2011 17:27        2\n",
       "3    4350           6   7/19/2011 21:37        2\n",
       "4    4355           1    8/2/2012 17:31        2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_df = pd.read_csv(test_dataset)\n",
    "test_input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-2-786796469737'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session = sage.Session()\n",
    "bucket=sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=sagemaker_session.upload_data(test_dataset, bucket=bucket, key_prefix='nba')\n",
    "test_data=sagemaker_session.upload_data(test_dataset, bucket=bucket, key_prefix='nba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Train a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that dataset is available in an accessible Amazon S3 bucket, we are ready to train a machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = 's3://{}/nba/{}'.format(bucket, 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information on creating an `Estimator` object, see [documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-02 09:45:35 Starting - Starting the training job...\n",
      "2021-03-02 09:45:58 Starting - Launching requested ML instancesProfilerReport-1614678335: InProgress\n",
      "......\n",
      "2021-03-02 09:46:59 Starting - Preparing the instances for training...\n",
      "2021-03-02 09:47:33 Downloading - Downloading input data\n",
      "2021-03-02 09:47:33 Training - Downloading the training image......\n",
      "2021-03-02 09:48:31 Training - Training image download completed. Training in progress..\u001b[34m2021-03-02 09:48:33.666628: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-02 09:48:33.666678: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mlist.remove(x): x not in list\u001b[0m\n",
      "\u001b[34mtotal chars: 6, target chars: 6\u001b[0m\n",
      "\u001b[34m{0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6}\u001b[0m\n",
      "\u001b[34mdivisor: 16569.971830985916\u001b[0m\n",
      "\u001b[34mdivisor2: 22087.183098591548\u001b[0m\n",
      "\u001b[34mnb sequences: 516\u001b[0m\n",
      "\u001b[34mVectorization...\u001b[0m\n",
      "\u001b[34mnum features: 11\u001b[0m\n",
      "\u001b[34mBuild model...\u001b[0m\n",
      "\u001b[34m2021-03-02 09:48:36.925197: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34m2021-03-02 09:48:36.926752: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-02 09:48:36.926773: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2021-03-02 09:48:36.926799: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-196-73.us-east-2.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2021-03-02 09:48:36.927228: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2021-03-02 09:48:36.927579: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34m2021-03-02 09:48:38.063994: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[34m2021-03-02 09:48:38.069113: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34mEpoch 1/10\u001b[0m\n",
      "\u001b[34m38/38 - 10s - loss: 3.2957 - act_output_loss: 1.8672 - time_output_loss: 1.4285 - val_loss: 2.5932 - val_act_output_loss: 1.5599 - val_time_output_loss: 1.0332\u001b[0m\n",
      "\u001b[34mEpoch 2/10\u001b[0m\n",
      "\u001b[34m38/38 - 1s - loss: 2.6797 - act_output_loss: 1.4194 - time_output_loss: 1.2603 - val_loss: 2.4077 - val_act_output_loss: 1.4413 - val_time_output_loss: 0.9663\u001b[0m\n",
      "\u001b[34mEpoch 3/10\u001b[0m\n",
      "\u001b[34m38/38 - 1s - loss: 2.3509 - act_output_loss: 1.2366 - time_output_loss: 1.1143 - val_loss: 2.2422 - val_act_output_loss: 1.3054 - val_time_output_loss: 0.9368\u001b[0m\n",
      "\u001b[34mEpoch 4/10\u001b[0m\n",
      "\u001b[34m38/38 - 1s - loss: 2.2323 - act_output_loss: 1.1551 - time_output_loss: 1.0772 - val_loss: 2.6325 - val_act_output_loss: 1.2867 - val_time_output_loss: 1.3458\u001b[0m\n",
      "\u001b[34mEpoch 5/10\u001b[0m\n",
      "\n",
      "2021-03-02 09:49:03 Uploading - Uploading generated training model\u001b[34m38/38 - 1s - loss: 2.1311 - act_output_loss: 1.0836 - time_output_loss: 1.0475 - val_loss: 2.4402 - val_act_output_loss: 1.2601 - val_time_output_loss: 1.1801\u001b[0m\n",
      "\u001b[34mEpoch 6/10\u001b[0m\n",
      "\u001b[34m38/38 - 1s - loss: 2.0510 - act_output_loss: 1.0399 - time_output_loss: 1.0111 - val_loss: 2.3072 - val_act_output_loss: 1.2816 - val_time_output_loss: 1.0256\u001b[0m\n",
      "\u001b[34mEpoch 7/10\u001b[0m\n",
      "\u001b[34m38/38 - 1s - loss: 1.9706 - act_output_loss: 0.9810 - time_output_loss: 0.9896 - val_loss: 2.2517 - val_act_output_loss: 1.1459 - val_time_output_loss: 1.1058\u001b[0m\n",
      "\u001b[34mEpoch 8/10\u001b[0m\n",
      "\u001b[34m38/38 - 1s - loss: 1.9352 - act_output_loss: 0.9711 - time_output_loss: 0.9641 - val_loss: 1.9587 - val_act_output_loss: 1.0057 - val_time_output_loss: 0.9530\u001b[0m\n",
      "\u001b[34mEpoch 9/10\u001b[0m\n",
      "\u001b[34m38/38 - 1s - loss: 1.8711 - act_output_loss: 0.9158 - time_output_loss: 0.9552 - val_loss: 2.2971 - val_act_output_loss: 1.3108 - val_time_output_loss: 0.9863\u001b[0m\n",
      "\u001b[34mEpoch 10/10\u001b[0m\n",
      "\u001b[34m38/38 - 2s - loss: 1.9202 - act_output_loss: 0.9806 - time_output_loss: 0.9396 - val_loss: 2.0571 - val_act_output_loss: 1.0377 - val_time_output_loss: 1.0194\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2021-03-02 09:49:21 Completed - Training job completed\n",
      "Training seconds: 111\n",
      "Billable seconds: 111\n"
     ]
    }
   ],
   "source": [
    "#Create an estimator object for running a training job\n",
    "estimator = sage.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=algo_arn,\n",
    "    base_job_name=\"nba\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    input_mode=\"File\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={}\n",
    ")\n",
    "#Run the training job.\n",
    "estimator.fit({\"training\": training_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this [blog-post](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/) for more information how to visualize metrics during the process. You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?#/jobs/) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Deploy model and verify results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can deploy the model for performing real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='nba-test'\n",
    "\n",
    "content_type='text/csv'\n",
    "\n",
    "real_time_inference_instance_type='ml.m5.large'\n",
    "batch_transform_inference_instance_type='ml.m5.large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Deploy trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "-------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(1, real_time_inference_instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint is created, you can perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = test_dataset\n",
    "output_file_name = \"nba_test_output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"text/csv; charset=utf-8\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name $predictor.endpoint \\\n",
    "    --body fileb://$file_name \\\n",
    "    --content-type $content_type \\\n",
    "    --region $sagemaker_session.boto_region_name \\\n",
    "    $output_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Case_id</th>\n",
       "      <th>nextStep</th>\n",
       "      <th>Time(mins)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4350</td>\n",
       "      <td>6</td>\n",
       "      <td>34.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4355</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4356</td>\n",
       "      <td>6</td>\n",
       "      <td>94.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4357</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4358</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Case_id  nextStep  Time(mins)\n",
       "0           0     4350         6       34.70\n",
       "1           1     4355         6        0.00\n",
       "2           2     4356         6       94.63\n",
       "3           3     4357         6        0.00\n",
       "4           4     4358         6        0.00"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.read_csv(output_file_name)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. you can terminate the same to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Perform Batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-786796469737/nba-test\n"
     ]
    }
   ],
   "source": [
    "#upload the batch-transform job input files to S3\n",
    "transform_input_folder = \"data/test\"\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder, key_prefix=model_name) \n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the batch-transform job\n",
    "transformer = model.transformer(1, batch_transform_inference_instance_type)\n",
    "transformer.transform(transform_input, content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output is available on following path\n",
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
